---
title: 'EDS 223: assignment 4'
author: "Sofia Ingersoll & Heather Childers"
date: "2023-12-8"
output:
    html_document:
      print_df: paged
      toc: yes
      toc_depth: 4
      toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
getwd()
```

## Overview

Marine aquaculture has the potential to play an important role in the global food supply as a more sustainable protein option than land-based meat production.[^1] [Gentry et al.](https://www.nature.com/articles/s41559-017-0257-9) mapped the potential for marine aquaculture globally based on multiple constraints, including ship traffic, dissolved oxygen, bottom depth .[^2]

[^1]: Hall, S. J., Delaporte, A., Phillips, M. J., Beveridge, M. & O'Keefe, M. Blue Frontiers: Managing the Environmental Costs of Aquaculture (The WorldFish Center, Penang, Malaysia, 2011).

[^2]: Gentry, R. R., Froehlich, H. E., Grimm, D., Kareiva, P., Parke, M., Rust, M., Gaines, S. D., & Halpern, B. S. Mapping the global potential for marine aquaculture. *Nature Ecology & Evolution*, 1, 1317-1324 (2017).

For this assignment, you are tasked with determining which Exclusive Economic Zones (EEZ) on the West Coast of the US are best suited to developing marine aquaculture for several species of oysters.\

Based on previous research, we know that oysters needs the following conditions for optimal growth:\

-   sea surface temperature: 11-30°C\
-   depth: 0-70 meters below sea level

##### Learning objectives:

-   combining vector/raster data\
-   resampling raster data\
-   masking raster data\
-   map algebra\

### Data

#### Sea Surface Temperature

We will use average annual sea surface temperature (SST) from the years 2008 to 2012 to characterize the average sea surface temperature within the region. The data we are working with was originally generated from [NOAA's 5km Daily Global Satellite Sea Surface Temperature Anomaly v3.1](https://coralreefwatch.noaa.gov/product/5km/index_5km_ssta.php).

#### Bathymetry

To characterize the depth of the ocean we will use the [General Bathymetric Chart of the Oceans (GEBCO)](https://www.gebco.net/data_and_products/gridded_bathymetry_data/#area).[^3]

[^3]: GEBCO Compilation Group (2022) GEBCO_2022 Grid (<doi:10.5285/e0f0bb80-ab44-2739-e053-6c86abc0289c>).

#### Exclusive Economic Zones

We will be designating maritime boundaries using Exclusive Economic Zones off of the west coast of US from [Marineregions.org](https://www.marineregions.org/eez.php).

## Assignment

Below is an outline of the steps you should consider taking to achieve the assignment tasks.

#### Prepare data (5 points)

To start, we need to load all necessary data and make sure it has the coordinate reference system.

-   load necessary packages and set path 
    -   I recommend using the [`here` package](https://here.r-lib.org/)

```{r message = FALSE}
# Loading libraries
library(sf)
library(tidyverse)
library(terra)
library(here)
library(tmap)
library(stars)
library(raster)
library(here)
rm(list = ls())
setwd(here())
```

-   read in the shapefile for the West Coast EEZ (`wc_regions_clean.shp`)

```{r}
# Reading in shapefile
wc_regions_clean <- st_read("data/wc_regions_clean.shp",
                            quiet = TRUE)
# Checking CRS
crs(wc_regions_clean)

# Visualizing Data
plot(wc_regions_clean["rgn_id"])
```

-   read in SST rasters
    -   `average_annual_sst_2008.tif`\
    -   `average_annual_sst_2009.tif`\
    -   `average_annual_sst_2010.tif`\
    -   `average_annual_sst_2011.tif`\
    -   `average_annual_sst_2012.tif`

```{r}
# Reading in rasters
#sst_08 <- read_stars("data/average_annual_sst_2008.tif") 
#sst_09 <- read_stars("data/average_annual_sst_2009.tif")
#sst_10 <- read_stars("data/average_annual_sst_2010.tif")
#sst_11 <- read_stars("data/average_annual_sst_2011.tif")
#sst_12 <- read_stars("data/average_annual_sst_2012.tif")

# Checkng CRS, shows evidence ofno projection
#st_crs(sst_08)
```

-   combine SST rasters into a raster stack

```{r}
# Combining SST rasters into raster stack

# object tifs names are stored in 
files_list <- c("data/average_annual_sst_2008.tif", 
                "data/average_annual_sst_2009.tif", 
                "data/average_annual_sst_2010.tif",
                "data/average_annual_sst_2011.tif", 
                "data/average_annual_sst_2012.tif")
# SpatRaster
sst_stack <- rast(files_list) %>% 
  project("EPSG:4326")

# Confirm all tifs in stack and projected correctly
sst_stack                        

plot(sst_stack)
```

-   read in bathymetry raster (`depth.tif`)

```{r}
# Reading in depth tif spatraster
depth <- read_stars("data/depth.tif")

# Checking crs, we see it's 4326
st_crs(depth)

# Visualizing depth shows it's not projecting correctly
plot(depth)

# output is NA, provides evidence that this tif is not properly being projected
crs(depth)

# Projecting CRS
depth <- rast(depth) %>% 
 project("EPSG:4326")

# Visualizing depth is now properly projected
plot(depth)
```

-   check that data are in the same coordinate reference system\
    -   reproject any data not in the same projection

```{r include=TRUE, warning=FALSE, messages=FALSE}
# Checking CRS
glimpse(crs(wc_regions_clean))
glimpse(crs(sst_stack))
glimpse(crs(depth))
```

#### Process data (10 points)

Next, we need process the SST and depth data so that they can be combined. In this case the SST and depth data have slightly different resolutions, extents, and positions. We don't want to change the underlying depth data, so we will need to resample to match the SST data using the nearest neighbor approach.

-   find the mean SST from 2008-2012

```{r}
# Finding the mean of the stack layers
mean_sst_stack <- mean(sst_stack, na.rm = TRUE)

plot(mean_sst_stack)
```

-   convert SST data from Kelvin to Celsius\
    -   hint: subtract by 273.15

```{r}
# Converting from Kelvin to Celcius
mean_sst_stack_c <- mean_sst_stack - 273.15 
mean_sst_stack_c
```

-   crop depth raster to match the extent of the SST raster
    -   note: the resolutions of the SST and depth data do not match

```{r}
depth
```

-   resample the NPP data to match the resolution of the SST data using the nearest neighbor approach

```{r}
# resampling depth to match mean_sst_stack resolution using nearest nbr
depth_resampled <- resample(depth, mean_sst_stack_c, method = "near")

# boolean test to see if resolutions match
resolution(depth_resampled) == resolution(mean_sst_stack_c)
```

-   check that the depth and SST match in resolution, extent, and coordinate reference system\
    -   hint: can the rasters be stacked?

```{r include=TRUE}
# confirming last step successful with stack
depth_sst <- c(mean_sst_stack_c, depth_resampled)

# plot not successful yet
plot(depth_sst)
```

#### Find suitable locations (20)

In order to find suitable locations for marine aquaculture, we'll need to find locations that are suitable in terms of both SST and depth.

-   reclassify SST and depth data into locations that are suitable for oysters
    -   hint: set suitable values to `1` and unsuitable values to `NA`

```{r}
# SST oyster locations
# reclassification matrix: binary raster where sst 11:30 degrees C = 1 (only show oyster friendly areas_)
rcl <- matrix(c(-Inf, 11, NA,
                11, 30, 1,
                30, Inf, NA), 
              ncol = 3,
              byrow = TRUE)

# reclassify tif
rcl_sst <- classify(mean_sst_stack_c, rcl = rcl)

# visualize 
plot(rcl_sst,
     col = "pink")

```

```{r}
# depth oyster locations
# reclassification matrix: binary raster where sst 0:70 ft C = 1 (only show oyster friendly areas)
rcl2 <- matrix(c(-Inf, -70, NA,
                 -70, 0, 1,
                 0, Inf, NA), 
              ncol = 3,
              byrow = TRUE)

# reclassify depth tif to only show oyster friendly areas
rcl_depth <- classify(depth_resampled, rcl = rcl2)

plot(rcl_depth)

```

-   find locations that satisfy both SST and depth conditions\
    -   hint: create an overlay using the `lapp()` function multiplying cell values

```{r include=TRUE}
# creating a function to multiply cell values 
fun = function(x,y) {
  return(x*y)
}

# creating a spatraster overlay by multiplying raster cell values
oyster_homes <- lapp(c(rcl_sst, rcl_depth),
                     fun = fun)
# visualize
plot(oyster_homes)
```

#### Determine the most suitable EEZ (20 points)

We want to determine the total suitable area within each EEZ in order to rank zones by priority. To do so, we need to find the total area of suitable locations within each EEZ.

-   select suitable cells within West Coast EEZs

```{r}
# combining and filtering for oyster areas
oyster_zones <- extract(oyster_homes, wc_regions_clean) # spatraster, vector with points we want to extract

# logical vector out of list
oyster_zones_vector <- unlist(oyster_zones)

# oyster mask adjusted to reflect suitable wc regions
oyster_homes[] <- NA
oyster_homes[oyster_zones_vector] <- 1

# Check that all values in oyster mask are either 1 or NA
if (all(
  unique(oyster_homes) %in% c(1, NA)
   )
  ) 
{
  print("Cool beans! The code ran successfully: our mask only contains values of 1 and NA.")
} else {
  stop("Uh oh! There's an error in the code: our mask contains values other than 1 or NA.")
  }
```

-   find the total suitable area within each EEZ
    -   hint: it might be helpful to rasterize the EEZ data
```{r}
# rasterize wc region data
eez <- rasterize(x = wc_regions_clean, 
                 y = mean_sst_stack_c,
                 field = 'rgn')                   # field to rasterize by rgn 

# make a mask
oyster_mask <- mask(eez, oyster_homes)

# cropped vector data
EEZ <- crop(oyster_mask, eez)
```

-   find area of grid cells

```{r}
# area of grid cells of west coast regions
cell_area <- cellSize(eez)

# calculate west coast areain rgns total area
eez_zonal_stats <- zonal(cell_area,
                     eez,
                     fun = 'sum',
                     na.rm = TRUE)
# check
eez_zonal_stats


# cell size of suitable areas in wcr
EEZ_cell_area <- cellSize(EEZ)
  
# calculate west coast areain rgns
EEZ_zonal_stats <- zonal(EEZ_cell_area,
                         EEZ,
                         fun = 'sum',
                         na.rm = TRUE)       
# check
EEZ_zonal_stats
```
-   find the percentage of each zone that is suitable\
    -   hint it might be helpful to join the suitable area by region onto the EEZ vector data

```{r include=TRUE}
# find percentage suitable areas
# creating a column for percent of suitable areas zonal stats
zonal_stats <- EEZ_zonal_stats %>%
  rename(suitable_area_km2 = area) %>%
  add_column(eez_zonal_stats$area) %>%
  rename(total_area_km2 = 'eez_zonal_stats$area') %>%
  mutate(pct_suitable = ((suitable_area/total_area)*100)) 

# confirm it did what we wanted
zonal_stats

# check calculated percents are 0:100
if (
  any(zonal_stats$pct_suitable < 0 | zonal_stats$pct_suitable > 100)
  ) 
  {
  stop("Uh oh! There's an error in the code: at least one percent area is not 0:100.")
} else {
  "Cool beans! The code ran successfully: all percents are within the valid range."
} 

# rasterize zonal stats & combine w/ og wcr data
zonal_stats_rast <- left_join(wc_regions_clean,
                              zonal_stats,
                              by = 'rgn')
glimpse(zonal_stats_rast)
```

#### Visualize results (5 points)

Now that we have results, we need to present them!

Create the following maps:

-   total suitable area by region

-   percent suitable area by region

Include:

-   legible legends\
-   updated color aesthetics\
-   basemap\

```{r include=TRUE}
# initiate tmap plottings
tmap_mode('plot')
#Create a map to plot the suitable area in km^2
tm_shape(zonal_stats_rast) +
  tm_polygons(fill = 'suitable_area', 
              fill_alpha = 0.6,                                             # Add geometry and opacity
              fill.scale = tm_scale(breaks = c(0,1000,2000,3000,4000,5000), # Add breaks, and legend title
                                    values = 'BuPu'),                       # Add Color scheme
              fill.legend = tm_legend(title = 'Suitable Area (km^2)')) +     # Add legend title
  tm_title(text = 'Suitable Area by Region: Oysters') +                     # Add figure title
  tm_scalebar(position = c('left','bottom')) +                              # Add a scalebar
  tm_basemap(server = 'OpenStreetMap')                                      # Add a basemap



 #tm_shape(no_blackout) + 
  #tm_polygons(fill = "median_income", 
   #       title = "Median Income ($)",
    #      palette = "magma") +
#  tm_borders() +
 # tm_title(text = "Median Income for Census Tracts Without Blackouts") +
  # tm_scalebar(position = c('right','bottom')) + 
#  tm_compass( type = 'rose', 
 #             lw = 0.,
  #            size = 2) 

```

```{r}
p1 <- ggplot(data = cpad_super) +
  geom_sf(aes(color = access_typ,
              fill = access_typ)) +
  theme_bw() +
  labs( color = "Access Type",     # need to put both or you get two legends
        fill = "Access Type") +
  annotation_scale(plot_unit = "km") + # this scale factor is very inaccurate
  annotaiton_north_arrow(
    location = 'tr',
    style = ggspatial::north_arrow_nautical(
      fill = c('grey40', 'white'),
      line_col = ('grey20')
    )
  ) +
  coord_sf() +# this sets coordinate system so it's following spatial and not catesian. best to add incase geom_sf doesn't properly call it on the backend 
  scale_color_viridis_d() +
  scale_fill_viridis_d()
```


#### Broaden your workflow! (40 points)

Now that you've worked through the solution for one group of species, let's update your workflow to work for other species. Please create a function that would allow you to reproduce your results for other species. Your function should be able to do the following:\

-   accept temperature and depth ranges and species name as inputs\
-   create maps of total suitable area and percent suitable area per EEZ with the species name in the title\

```{r}
#------------------------------------------------------------------------Maxtrix & reclassification
# SST oyster locations
# reclassification matrix: binary raster where sst 11:30 degrees C = 1 (only show squid friendly areas_)
rcl3 <- matrix(c(-Inf, 11, NA,
                11, 30, 1,
                30, Inf, NA), 
              ncol = 3,
              byrow = TRUE)

# reclassify tif
rcl_sst2 <- classify(mean_sst_stack_c, rcl = rcl3)

# visualize 
plot(rcl_sst2,
     col = "pink")

# depth oyster locations
# reclassification matrix: binary raster where sst 0:70 ft C = 1 (only show squid friendly areas)
rcl4 <- matrix(c(-Inf, -70, NA,
                 -70, 0, 1,
                 0, Inf, NA), 
              ncol = 3,
              byrow = TRUE)

# reclassify depth tif to only show oyster friendly areas
rcl_depth2 <- classify(depth_resampled, rcl = rcl4)

plot(rcl_depth2)

#--------------------------------------------------------------------------Overlaying rasters
# creating a spatraster overlay by multiplying raster cell values
squid_homes <- lapp(c(rcl_sst2, rcl_depth2),
                     fun = fun)

plot(squid_homes)
#--------------------------------------------------------------------------Masking for squid friendly areas
# combining and filtering for oyster areas
squid_zones <- extract(squid_homes, wc_regions_clean) # spatraster, vector with points we want to extract

# logical vector out of list
squid_zones_vector <- unlist(squid_zones)

# squid mask adjusted to reflect suitable wc regions turned into boolean
squid_homes[] <- NA
squid_homes[squid_zones_vector] <- 1

# make a mask
squid_mask <- mask(eez, squid_homes)

# cropped vector data
EEZ2 <- crop(squid_mask, eez)

# plot 
plot(EEZ2)

#--------------------------------------------------------------------------Zonal stats 
# find percentage suitable areas
# creating a column for percent of suitable areas zonal stats
zonal_stats2 <- EEZ_zonal_stats %>%
  rename(suitable_area = area) %>%
  add_column(eez_zonal_stats$area) %>%
  rename(total_area = 'eez_zonal_stats$area') %>%
  mutate(pct_suitable = ((suitable_area/total_area)*100))

# confirm it did what we wanted
zonal_stats

# rasterize zonal stats & combine w/ og wcr data
zonal_stats_rast <- left_join(wc_regions_clean,
                              zonal_stats,
                              by = 'rgn')
glimpse(zonal_stats_rast)

```

```{r}
#------------------------------------------------------------------------Maxtrix & reclassification
# SST oyster locations
# reclassification matrix: binary raster where sst 11:30 degrees C = 1 (only show squid friendly areas_)
rcl3 <- matrix(c(-Inf, 11, NA,
                11, 30, 1,
                30, Inf, NA), 
              ncol = 3,
              byrow = TRUE)

# reclassify tif
rcl_sst2 <- classify(mean_sst_stack_c, rcl = rcl3)

# visualize 
plot(rcl_sst2,
     col = "pink")

# depth oyster locations
# reclassification matrix: binary raster where sst 0:70 ft C = 1 (only show squid friendly areas)
rcl4 <- matrix(c(-Inf, -70, NA,
                 -70, 0, 1,
                 0, Inf, NA), 
              ncol = 3,
              byrow = TRUE)

# reclassify depth tif to only show oyster friendly areas
rcl_depth2 <- classify(depth_resampled, rcl = rcl4)

plot(rcl_depth2)


squid_areas <- function(polygon, raster, m_layer, m_label) {
  #raserize polygon by layer -- this gives us resolution and data on layers
  id_rast = rasterize(polygon, raster, field = 'suid_nma')

   # do mean zonal stats, double << assignment operater allows output to be "global" vs others that are only accessible using tis function
  zonal_layer <<- zonal(raster, id_rast, fun = "mean", na.rm = TRUE)                   
  
  # join withpolygon database
  poly_join <<- full_join(polygon, zonal_layer) %>% 
    select(suid_na, gHM, paste(my_layer))            # paste this as a recognizable layer to access
}


  # create boxplot based on layer
  p1 <- ggplot(poly_join) 
```


Run your function for a species of your choice! You can find information on species depth and temperature requirements on [SeaLifeBase](https://www.sealifebase.ca/search.php). Remember, we are thinking about the potential for marine aquaculture, so these species should have some reasonable potential for commercial consumption.

<https://www.sealifebase.ca/Country/CountrySpeciesSummary.php?c_code=840&id=57476>
